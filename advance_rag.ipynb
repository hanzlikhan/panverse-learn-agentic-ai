{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPysiWOveQj6VX4LJlY6bGM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cbfc2834a25e466aa9f0b9a765dbbacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5db41a9b21e34665ab68c2e9a8f8594f",
              "IPY_MODEL_905bc53f565e423e9baf615a9b70c3db",
              "IPY_MODEL_f3510f8149604598ad60fa6d9baf750f"
            ],
            "layout": "IPY_MODEL_5a780449c663490a91d66f6ed69b0459"
          }
        },
        "5db41a9b21e34665ab68c2e9a8f8594f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7871f8d4b3ec4878be2540a1a03b0325",
            "placeholder": "​",
            "style": "IPY_MODEL_8be7f5215e0c4f0d932cc2fe8aec8aa5",
            "value": "100%"
          }
        },
        "905bc53f565e423e9baf615a9b70c3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb0b34dab0e6456cb85a849db20a3581",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bd7f3c8ff8743f0a600e0af761c8c4b",
            "value": 111898327
          }
        },
        "f3510f8149604598ad60fa6d9baf750f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c1d12f63d184032a1b51cb92981af87",
            "placeholder": "​",
            "style": "IPY_MODEL_85bcbe8f28ff404fa94da8b58f11f594",
            "value": " 107M/107M [00:01&lt;00:00, 107MB/s]"
          }
        },
        "5a780449c663490a91d66f6ed69b0459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7871f8d4b3ec4878be2540a1a03b0325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8be7f5215e0c4f0d932cc2fe8aec8aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb0b34dab0e6456cb85a849db20a3581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bd7f3c8ff8743f0a600e0af761c8c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c1d12f63d184032a1b51cb92981af87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85bcbe8f28ff404fa94da8b58f11f594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanzlikhan/panverse-learn-agentic-ai/blob/main/advance_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngSxKtAv8UDW"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "genai.configure(api_key = userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "Rqmrnpg78keQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(genai.list_models())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9FShYOeb88Sb",
        "outputId": "0b8df02d-396e-4d03-99ac-1f8b793ece98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro 001',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "       description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                    'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=16384,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
              "       description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
              "       description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.5-pro-exp-03-25',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini 2.5 Pro Experimental 03-25',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash',\n",
              "       description='Gemini 2.0 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash 001',\n",
              "       description=('Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in January of 2025.'),\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp-image-generation',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash (Image Generation) Experimental',\n",
              "       description='Gemini 2.0 Flash (Image Generation) Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash-Lite 001',\n",
              "       description='Stable version of Gemini 2.0 Flash Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash-Lite',\n",
              "       description='Gemini 2.0 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-preview-02-05',\n",
              "       base_model_id='',\n",
              "       version='preview-02-05',\n",
              "       display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
              "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-preview',\n",
              "       base_model_id='',\n",
              "       version='preview-02-05',\n",
              "       display_name='Gemini 2.0 Flash-Lite Preview',\n",
              "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-pro-exp',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini 2.0 Pro Experimental',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-pro-exp-02-05',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini 2.0 Pro Experimental 02-05',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-01-21',\n",
              "       base_model_id='',\n",
              "       version='2.0-exp-01-21',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental 01-21',\n",
              "       description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0-exp-01-21',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental 01-21',\n",
              "       description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-1.5-pro-experimental',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='LearnLM 1.5 Pro Experimental',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
              "                    'mid-size multimodal model that supports up to 2 million tokens.'),\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-27b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 27B',\n",
              "       description='',\n",
              "       input_token_limit=131072,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-embedding-exp-03-07',\n",
              "       base_model_id='',\n",
              "       version='exp-03-07',\n",
              "       display_name='Gemini Embedding Experimental 03-07',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-embedding-exp',\n",
              "       base_model_id='',\n",
              "       version='exp-03-07',\n",
              "       display_name='Gemini Embedding Experimental',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40),\n",
              " Model(name='models/imagen-3.0-generate-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Imagen 3.0 002 model',\n",
              "       description='Vertex served Imagen 3.0 002 model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# problems\n",
        "1. retrieval query\n",
        "2. retrieval document\n",
        "3. classification\n",
        "4. clustering\n",
        "5. Semantic similarity"
      ],
      "metadata": {
        "id": "GfBHY9Os_Udw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single line embeddings"
      ],
      "metadata": {
        "id": "awxxKcCACcST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model = \"models/text-embedding-004\",\n",
        "    content = \"what is the meaning of life?\",\n",
        "    task_type = \"retrieval_document\",\n",
        "    title = \"Embedding of single string\"\n",
        "\n",
        ")\n",
        "\n",
        "# # 1 input > 1 vector ouput\n",
        "# print(str(result[\"embedding of single string\"]))\n",
        "\n",
        "len(result['embedding'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "p0vBahh-9vk-",
        "outputId": "c0cf2690-6ff5-49b3-f284-cf4a4d84aa3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "result : Dict = genai.embed_content(\n",
        "    model = \"models/text-embedding-004\",\n",
        "    content = [\n",
        "        \"what is the meaning of life?\",\n",
        "        \"how much would a woodchuck chuck?\",\n",
        "        \"how does the brain work?\",\n",
        "    ],\n",
        "    task_type = \"retrieval_document\",\n",
        "    title = \"Embedding of list of strings\"\n",
        ")\n",
        "# A list of input > A list of vectors output\n",
        "for v in result[\"embedding\"]:\n",
        "  print(str(v)[:50], \"... TRIMMED ...\", len(v))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "hanWm_7x_HFD",
        "outputId": "223004cb-4da2-45eb-d94b-e71583b48f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.035072885, 0.029919365, -0.038117167, -0.00390 ... TRIMMED ... 768\n",
            "[-0.003879107, 0.021470599, -0.08200075, -0.013340 ... TRIMMED ... 768\n",
            "[0.0040124026, 0.036846075, -0.1233212, -0.0100360 ... TRIMMED ... 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# langchain databases for the rag\n",
        "- it is necessary for rag to use any database to store\n",
        "\n",
        "# Building Vector Stores & Retreival usig Chroma DB and Langchain"
      ],
      "metadata": {
        "id": "ZCRxGeqNGf0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW4v_ChPDfFN",
        "outputId": "3c900398-0926-4730-c72e-ef1b7ad67f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "mR9LUiVBGs5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content = \"Dogs are great compannions , known for their loyalty and friendliness\",\n",
        "        metadata = {\"source\": \"memmal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content = \"Cats are independent pets that ofte enjoy their ownn space.\",\n",
        "        metadata = {\"source\": \"memmal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content = \"Goldfish are popular pets for beginnners, requirinng relatively simple care.\",\n",
        "        metadata = {\"source\": \"fish-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content = \"Parrots are intelligent birds capable of mimickig human speech.\",\n",
        "        metadata={\"source\":\"bird-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content = \"Rabbits are social animals that need plenty of space to hop around.\",\n",
        "        metadata={\"source\":\"mammal-pets-doc\"}\n",
        "    ),\n",
        "\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "aRPEjhbcJKnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# langchainn"
      ],
      "metadata": {
        "id": "bu33ZRaENrNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -uq langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzIP0GOsKg8g",
        "outputId": "8074b280-ad16-47dc-8ceb-4aafee12ff76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrPckBTcQ7Ot",
        "outputId": "a301bd89-eb8c-4aa4-8bff-c4f55559d552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "_iMaCZfTRQbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "# embeddings.embed_query('what's our Q1 revenue')\n"
      ],
      "metadata": {
        "id": "o_DsWOkmNoNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.embed_query(\"what's our Q1 revenue\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT7phpPPPd8J",
        "outputId": "25f4c195-52d2-4773-e41f-fb7236b3f93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03465051203966141,\n",
              " -0.005352395586669445,\n",
              " -0.013069725595414639,\n",
              " -0.0012986029032617807,\n",
              " 0.046841446310281754,\n",
              " 0.048569560050964355,\n",
              " -0.017582688480615616,\n",
              " -0.04050964117050171,\n",
              " -0.02819770947098732,\n",
              " -0.014740178361535072,\n",
              " 0.005013409536331892,\n",
              " -0.003409329103305936,\n",
              " 0.07643156498670578,\n",
              " -0.00673871161416173,\n",
              " 0.03565828502178192,\n",
              " -0.02149534784257412,\n",
              " -0.022696996107697487,\n",
              " -0.00774530740454793,\n",
              " -0.1538902223110199,\n",
              " -0.006498429924249649,\n",
              " 0.027820764109492302,\n",
              " -0.0028050686232745647,\n",
              " -0.024349454790353775,\n",
              " -0.02384689636528492,\n",
              " -0.03655124455690384,\n",
              " -0.0672861635684967,\n",
              " 0.0077889966778457165,\n",
              " 0.004447615705430508,\n",
              " 0.0025132503360509872,\n",
              " -0.00831856019794941,\n",
              " 0.009702443145215511,\n",
              " 0.0035754439886659384,\n",
              " -0.05084170401096344,\n",
              " -0.052662063390016556,\n",
              " -0.022010959684848785,\n",
              " 0.030220316722989082,\n",
              " -0.04195867478847504,\n",
              " 0.06849957257509232,\n",
              " 0.017826495692133904,\n",
              " -0.06258358061313629,\n",
              " -0.035857975482940674,\n",
              " -0.011730403639376163,\n",
              " -0.033875346183776855,\n",
              " -0.0027217536699026823,\n",
              " 0.03412327542901039,\n",
              " 0.0025415190029889345,\n",
              " -0.0035778654273599386,\n",
              " 0.016955584287643433,\n",
              " 0.0044281804002821445,\n",
              " 0.001660540932789445,\n",
              " -0.017266184091567993,\n",
              " -0.04488421976566315,\n",
              " -0.015456323511898518,\n",
              " 0.005353156011551619,\n",
              " -0.04309507831931114,\n",
              " -0.02332034520804882,\n",
              " 0.023036977276206017,\n",
              " -0.0075400760397315025,\n",
              " 0.09763869643211365,\n",
              " -0.004600197076797485,\n",
              " 0.024307291954755783,\n",
              " 0.001209727954119444,\n",
              " 0.05049135908484459,\n",
              " -0.00656031584367156,\n",
              " 0.0228818878531456,\n",
              " -0.029320087283849716,\n",
              " 0.0369061678647995,\n",
              " 0.014213685877621174,\n",
              " -0.07624918967485428,\n",
              " -0.031669147312641144,\n",
              " -0.021932333707809448,\n",
              " 0.05277204141020775,\n",
              " 0.005983940791338682,\n",
              " -0.03647455945611,\n",
              " -0.0013518225168809295,\n",
              " 0.0034830160439014435,\n",
              " 0.00024570038658566773,\n",
              " -0.04762881249189377,\n",
              " 0.02669118158519268,\n",
              " 0.08305687457323074,\n",
              " -0.05599955469369888,\n",
              " 0.013541709631681442,\n",
              " 0.07478064298629761,\n",
              " 0.008495342917740345,\n",
              " 0.04162329062819481,\n",
              " -0.013255508616566658,\n",
              " -0.05033194646239281,\n",
              " -0.04057135060429573,\n",
              " -0.05990063399076462,\n",
              " -0.02606894075870514,\n",
              " 0.06469349563121796,\n",
              " -0.038383789360523224,\n",
              " -0.01970384642481804,\n",
              " -0.03014085255563259,\n",
              " 0.07999791204929352,\n",
              " -0.06230812892317772,\n",
              " -0.08551579713821411,\n",
              " -0.047862667590379715,\n",
              " 0.06381496787071228,\n",
              " 0.0688355416059494,\n",
              " 0.009681832045316696,\n",
              " -0.03359870985150337,\n",
              " 0.012767596170306206,\n",
              " 0.017601191997528076,\n",
              " 0.038839928805828094,\n",
              " -0.0037070775870233774,\n",
              " -0.02569352462887764,\n",
              " 0.006130817346274853,\n",
              " -0.030217336490750313,\n",
              " -0.015551178716123104,\n",
              " -0.02732756920158863,\n",
              " -0.036633241921663284,\n",
              " -0.0005332095315679908,\n",
              " -0.025133304297924042,\n",
              " 0.012585081160068512,\n",
              " 0.007354916539043188,\n",
              " -0.02948826178908348,\n",
              " 0.01500996295362711,\n",
              " -0.008615933358669281,\n",
              " 0.0160839781165123,\n",
              " 0.05758240073919296,\n",
              " 0.023404885083436966,\n",
              " -0.007515374105423689,\n",
              " 0.0380786769092083,\n",
              " 0.03036392293870449,\n",
              " 0.014527580700814724,\n",
              " 0.04709804803133011,\n",
              " 0.009368544444441795,\n",
              " -0.04337659850716591,\n",
              " -0.04648466780781746,\n",
              " -0.02312665991485119,\n",
              " 0.001884583616629243,\n",
              " 0.007531610317528248,\n",
              " -0.007580536417663097,\n",
              " 0.02932310849428177,\n",
              " -0.02655649371445179,\n",
              " 0.0905970111489296,\n",
              " 0.04178284853696823,\n",
              " -0.030519472435116768,\n",
              " 0.027087215334177017,\n",
              " 0.039237070828676224,\n",
              " -0.039013076573610306,\n",
              " -0.05530824512243271,\n",
              " 0.015051903203129768,\n",
              " -0.018945930525660515,\n",
              " -0.02050071209669113,\n",
              " 0.025464428588747978,\n",
              " 0.012419999577105045,\n",
              " -0.02586180344223976,\n",
              " -0.022281337529420853,\n",
              " -0.03949360549449921,\n",
              " 0.005184507463127375,\n",
              " -0.015287728048861027,\n",
              " -0.017613418400287628,\n",
              " 0.04838521033525467,\n",
              " 0.006975100841373205,\n",
              " 0.0003137126623187214,\n",
              " 0.03182576596736908,\n",
              " 0.046838462352752686,\n",
              " 0.03316700831055641,\n",
              " -0.04161476343870163,\n",
              " 0.009966033510863781,\n",
              " -0.019715705886483192,\n",
              " 0.02943940833210945,\n",
              " -0.04010942950844765,\n",
              " 0.006571561098098755,\n",
              " -0.026850728318095207,\n",
              " -0.001875448739156127,\n",
              " 0.03740917891263962,\n",
              " 0.00837355013936758,\n",
              " -0.024028833955526352,\n",
              " -0.036702778190374374,\n",
              " -0.05421479418873787,\n",
              " -0.07598255574703217,\n",
              " -0.027154026553034782,\n",
              " 0.07540398836135864,\n",
              " -0.004565841984003782,\n",
              " -0.05111896991729736,\n",
              " -0.12299113720655441,\n",
              " -0.06985802948474884,\n",
              " 0.03921249136328697,\n",
              " 0.018969791010022163,\n",
              " -0.051003288477659225,\n",
              " -0.012252799235284328,\n",
              " 0.060772329568862915,\n",
              " 0.03412419185042381,\n",
              " 0.007625380996614695,\n",
              " -0.030145222321152687,\n",
              " -0.020544568076729774,\n",
              " 0.008922155015170574,\n",
              " -0.015060832723975182,\n",
              " 0.0006857500993646681,\n",
              " 0.03525032103061676,\n",
              " -0.04717588424682617,\n",
              " 0.007510920986533165,\n",
              " 0.04140608012676239,\n",
              " 0.045437291264534,\n",
              " -0.028624283149838448,\n",
              " -0.04204718768596649,\n",
              " 0.006169473752379417,\n",
              " -0.01313267182558775,\n",
              " -0.0343688428401947,\n",
              " 0.015489374287426472,\n",
              " -0.06334272772073746,\n",
              " -0.036941248923540115,\n",
              " -0.031392429023981094,\n",
              " -0.04431218281388283,\n",
              " -0.01786382496356964,\n",
              " -0.04780622944235802,\n",
              " -0.0013033997965976596,\n",
              " 0.023237718269228935,\n",
              " 0.015678266063332558,\n",
              " -0.04980039596557617,\n",
              " -0.05636771768331528,\n",
              " 0.0033836166840046644,\n",
              " 0.02620573528110981,\n",
              " 0.0705796405673027,\n",
              " 0.01700187660753727,\n",
              " 0.0019983549136668444,\n",
              " -0.018984336405992508,\n",
              " 0.025281911715865135,\n",
              " -0.012376632541418076,\n",
              " 0.03397761285305023,\n",
              " -0.0161396823823452,\n",
              " 0.02370881289243698,\n",
              " 0.013972734101116657,\n",
              " 0.0198037289083004,\n",
              " 0.01261997502297163,\n",
              " -0.03190207481384277,\n",
              " -0.021594112738966942,\n",
              " 0.04246775805950165,\n",
              " 0.0036560012958943844,\n",
              " -0.04663238674402237,\n",
              " 0.036417461931705475,\n",
              " -0.027908096089959145,\n",
              " 0.07492285221815109,\n",
              " 0.032215017825365067,\n",
              " 0.01660180650651455,\n",
              " 0.028981564566493034,\n",
              " -0.057832565158605576,\n",
              " -0.021699784323573112,\n",
              " -0.013158649206161499,\n",
              " -0.020110227167606354,\n",
              " 0.004849477205425501,\n",
              " -0.015630105510354042,\n",
              " -0.0030568824149668217,\n",
              " 0.05478451028466225,\n",
              " 0.016873132437467575,\n",
              " -0.0132520766928792,\n",
              " -0.035431139171123505,\n",
              " -0.06389930099248886,\n",
              " 0.016586173325777054,\n",
              " 0.0067534069530665874,\n",
              " 0.0238955058157444,\n",
              " -0.05148904770612717,\n",
              " -0.003934098407626152,\n",
              " 0.00796580407768488,\n",
              " -0.06489622592926025,\n",
              " 0.0073846736922860146,\n",
              " 0.07456008344888687,\n",
              " 0.029385987669229507,\n",
              " -0.05259881168603897,\n",
              " -0.003024352015927434,\n",
              " -0.04500965029001236,\n",
              " -0.05706910789012909,\n",
              " -0.07159323990345001,\n",
              " -0.04288385435938835,\n",
              " -0.029540665447711945,\n",
              " 0.018584484234452248,\n",
              " 0.01150582730770111,\n",
              " 0.004051439929753542,\n",
              " 0.009150581434369087,\n",
              " -0.04207849130034447,\n",
              " 0.013484221883118153,\n",
              " 0.0029293347615748644,\n",
              " -0.020906677469611168,\n",
              " -0.031348880380392075,\n",
              " 0.017658747732639313,\n",
              " -0.022727588191628456,\n",
              " 0.03284049406647682,\n",
              " 0.04014531150460243,\n",
              " -0.005892286542803049,\n",
              " 0.02237272448837757,\n",
              " -0.04126352444291115,\n",
              " 0.013100813142955303,\n",
              " 0.012476982548832893,\n",
              " 0.01178724318742752,\n",
              " 0.05447802692651749,\n",
              " 0.022451553493738174,\n",
              " -0.03758685290813446,\n",
              " -0.003238242818042636,\n",
              " -0.01656155101954937,\n",
              " -0.020356932654976845,\n",
              " -0.012708253227174282,\n",
              " 0.028322823345661163,\n",
              " 0.049915023148059845,\n",
              " 0.05238070711493492,\n",
              " 0.007685909513384104,\n",
              " 0.014549067243933678,\n",
              " 0.023123789578676224,\n",
              " 0.02430092543363571,\n",
              " -0.00799862015992403,\n",
              " 0.02740553393959999,\n",
              " 0.05758802592754364,\n",
              " 0.07900919765233994,\n",
              " 0.02223963476717472,\n",
              " -0.007350119762122631,\n",
              " -0.07667933404445648,\n",
              " -0.0717344805598259,\n",
              " -0.009185811504721642,\n",
              " 0.027595030143857002,\n",
              " -0.04549090936779976,\n",
              " -0.031427051872015,\n",
              " -0.0448775440454483,\n",
              " -0.018655110150575638,\n",
              " -0.0068896375596523285,\n",
              " -0.08957657217979431,\n",
              " -0.025464825332164764,\n",
              " -0.04845375195145607,\n",
              " -0.052280768752098083,\n",
              " 0.04210411012172699,\n",
              " -0.03379722312092781,\n",
              " -0.0613868273794651,\n",
              " -0.027474012225866318,\n",
              " 0.05797427520155907,\n",
              " 0.020904572680592537,\n",
              " 0.007242858409881592,\n",
              " 0.03207658231258392,\n",
              " -0.06351438909769058,\n",
              " -0.04532288759946823,\n",
              " -0.01730777695775032,\n",
              " -0.007889727130532265,\n",
              " -0.0008333199075423181,\n",
              " -0.03261425346136093,\n",
              " 0.009455125778913498,\n",
              " 0.03621084615588188,\n",
              " -0.05500786378979683,\n",
              " 0.03334052488207817,\n",
              " 0.05987250432372093,\n",
              " 0.031935080885887146,\n",
              " 0.027699237689375877,\n",
              " 0.0504794642329216,\n",
              " 0.03885986655950546,\n",
              " 0.03870648890733719,\n",
              " -0.023922601714730263,\n",
              " 0.007826179265975952,\n",
              " 0.03739505633711815,\n",
              " 0.0268231350928545,\n",
              " -0.023310789838433266,\n",
              " -0.01404209528118372,\n",
              " 0.010225166566669941,\n",
              " 0.06577572971582413,\n",
              " 0.015546770766377449,\n",
              " -0.022921396419405937,\n",
              " -0.012964093126356602,\n",
              " -0.008787899278104305,\n",
              " 0.0434652715921402,\n",
              " 0.023191679269075394,\n",
              " 0.017399266362190247,\n",
              " 0.004979859106242657,\n",
              " 0.027402836829423904,\n",
              " -0.024701233953237534,\n",
              " -0.04184333607554436,\n",
              " -0.012404710054397583,\n",
              " -0.02626343071460724,\n",
              " 0.03461303934454918,\n",
              " 0.021697310730814934,\n",
              " 0.041739899665117264,\n",
              " -0.006934312172234058,\n",
              " 0.0009607240208424628,\n",
              " -0.016374096274375916,\n",
              " -0.0328129418194294,\n",
              " 0.03251843899488449,\n",
              " 0.03000706247985363,\n",
              " -0.012184781953692436,\n",
              " -0.04874863103032112,\n",
              " -0.05354081466794014,\n",
              " -0.002417398616671562,\n",
              " 0.028366515412926674,\n",
              " -0.025864163413643837,\n",
              " 0.050339750945568085,\n",
              " 0.002379080979153514,\n",
              " -0.04696089029312134,\n",
              " 0.07070761919021606,\n",
              " -0.04232018068432808,\n",
              " 0.009713404811918736,\n",
              " -0.07100173085927963,\n",
              " -0.018662264570593834,\n",
              " 0.013940622098743916,\n",
              " -0.04223143309354782,\n",
              " 0.00022400269517675042,\n",
              " 0.0065766614861786366,\n",
              " 0.022038888186216354,\n",
              " 0.03461229428648949,\n",
              " -0.002655633259564638,\n",
              " 0.06368900835514069,\n",
              " -0.01251563522964716,\n",
              " -0.01431681402027607,\n",
              " 0.02105231024324894,\n",
              " -0.03469380363821983,\n",
              " -0.031201614066958427,\n",
              " -0.017892511561512947,\n",
              " -9.23679763218388e-05,\n",
              " -0.03180892392992973,\n",
              " -0.021484922617673874,\n",
              " -0.02523389831185341,\n",
              " 0.057138413190841675,\n",
              " -0.005749361589550972,\n",
              " -0.007679418660700321,\n",
              " -0.03841867297887802,\n",
              " 0.06624823808670044,\n",
              " 0.023860780522227287,\n",
              " -0.03714216500520706,\n",
              " 0.0007747490890324116,\n",
              " -0.043011292815208435,\n",
              " -0.0005978606641292572,\n",
              " 0.0055801402777433395,\n",
              " -0.006431419402360916,\n",
              " 0.045629773288965225,\n",
              " -0.002101137302815914,\n",
              " 0.012788496911525726,\n",
              " -0.018041634932160378,\n",
              " 0.05752263963222504,\n",
              " -0.02802460826933384,\n",
              " 0.02007678896188736,\n",
              " -0.005466299131512642,\n",
              " -0.0028336760587990284,\n",
              " 0.01145404763519764,\n",
              " 0.035370465368032455,\n",
              " 0.0004378891608212143,\n",
              " -0.03842204064130783,\n",
              " 0.014645843766629696,\n",
              " -0.03494250029325485,\n",
              " -0.019235743209719658,\n",
              " -0.07472031563520432,\n",
              " 0.004751075524836779,\n",
              " -0.013066157698631287,\n",
              " 0.04439971223473549,\n",
              " 0.00570489838719368,\n",
              " -0.02964862249791622,\n",
              " 0.01921737752854824,\n",
              " 0.02079877257347107,\n",
              " 0.054746489971876144,\n",
              " 0.026148255914449692,\n",
              " -0.006675942335277796,\n",
              " 0.01087565440684557,\n",
              " -0.009113010950386524,\n",
              " 0.02749793231487274,\n",
              " -0.05147945508360863,\n",
              " -0.00421088095754385,\n",
              " 0.0013130024308338761,\n",
              " 0.010480741038918495,\n",
              " 0.04649261757731438,\n",
              " -0.03739802911877632,\n",
              " -0.039036087691783905,\n",
              " -0.007778955157846212,\n",
              " -0.02331644669175148,\n",
              " 0.04576808214187622,\n",
              " 0.005966843105852604,\n",
              " 0.0196416936814785,\n",
              " -0.0037963036447763443,\n",
              " -0.022628789767622948,\n",
              " 0.039008334279060364,\n",
              " 0.026647105813026428,\n",
              " -0.002972440328449011,\n",
              " -0.045252475887537,\n",
              " 0.010288644582033157,\n",
              " -0.007385986391454935,\n",
              " -0.010360019281506538,\n",
              " 0.08008964359760284,\n",
              " 0.04817844182252884,\n",
              " -0.013582336716353893,\n",
              " 0.005895373411476612,\n",
              " -0.02765418216586113,\n",
              " -0.01800358295440674,\n",
              " 0.012390966527163982,\n",
              " -0.05390556901693344,\n",
              " -0.04413276165723801,\n",
              " -0.07719185948371887,\n",
              " -0.024848172441124916,\n",
              " 0.006219953298568726,\n",
              " -0.0634637326002121,\n",
              " -0.04563501849770546,\n",
              " 0.057285457849502563,\n",
              " 0.02715013176202774,\n",
              " -0.013734905049204826,\n",
              " 0.003271804889664054,\n",
              " -0.013485142029821873,\n",
              " 0.07085631042718887,\n",
              " -0.015327340923249722,\n",
              " 0.018910324200987816,\n",
              " 0.011836531572043896,\n",
              " -0.002747794846072793,\n",
              " -0.046890366822481155,\n",
              " -0.062026720494031906,\n",
              " -0.012518147937953472,\n",
              " 0.045270610600709915,\n",
              " 0.006405222229659557,\n",
              " -0.034056104719638824,\n",
              " 0.019962770864367485,\n",
              " 0.013827025890350342,\n",
              " 0.03407280147075653,\n",
              " -0.006649376358836889,\n",
              " -0.036570239812135696,\n",
              " -0.022449349984526634,\n",
              " -0.05598219484090805,\n",
              " -0.04080554097890854,\n",
              " -0.014494289644062519,\n",
              " -0.0032335936557501554,\n",
              " -0.004369655158370733,\n",
              " 0.006541041191667318,\n",
              " -0.046499691903591156,\n",
              " 0.029578493908047676,\n",
              " 0.06313948333263397,\n",
              " 0.006610180251300335,\n",
              " 0.0432535745203495,\n",
              " -0.052607130259275436,\n",
              " 0.04430235177278519,\n",
              " -0.0028148877900093794,\n",
              " -0.01874277926981449,\n",
              " -0.1015489250421524,\n",
              " -0.011643759906291962,\n",
              " 0.04326939955353737,\n",
              " -0.0036822380498051643,\n",
              " 0.013441083952784538,\n",
              " -0.016577033326029778,\n",
              " -0.0757485032081604,\n",
              " -0.025432517752051353,\n",
              " 0.005091668572276831,\n",
              " 0.013275176286697388,\n",
              " 0.027563828974962234,\n",
              " 0.03285320848226547,\n",
              " 0.03371916711330414,\n",
              " 0.01300343219190836,\n",
              " -0.04219444841146469,\n",
              " 0.018151946365833282,\n",
              " 0.0253815408796072,\n",
              " -0.010489257983863354,\n",
              " -0.016577906906604767,\n",
              " 0.032945796847343445,\n",
              " 0.04662322998046875,\n",
              " -0.02819127030670643,\n",
              " 0.015065479092299938,\n",
              " 0.04026106745004654,\n",
              " 0.03194551169872284,\n",
              " 0.04546308144927025,\n",
              " 0.023399585857987404,\n",
              " -0.05734328553080559,\n",
              " 0.004350164905190468,\n",
              " 0.03188121318817139,\n",
              " -0.017640752717852592,\n",
              " -0.057695548981428146,\n",
              " 0.003585873870179057,\n",
              " -0.007145263720303774,\n",
              " 0.07162812352180481,\n",
              " -0.008557289838790894,\n",
              " 0.017736677080392838,\n",
              " 0.02521919459104538,\n",
              " 0.0065681892447173595,\n",
              " -0.03470686078071594,\n",
              " 0.06678922474384308,\n",
              " -0.015008504502475262,\n",
              " 0.017285946756601334,\n",
              " -0.05474315956234932,\n",
              " -0.0024022713769227266,\n",
              " 0.005906973499804735,\n",
              " 0.0419621467590332,\n",
              " 0.12230692058801651,\n",
              " 0.0007289979257620871,\n",
              " -0.06306730955839157,\n",
              " 0.09365107119083405,\n",
              " -0.0053116437047719955,\n",
              " -0.03853898495435715,\n",
              " -0.0417933315038681,\n",
              " 0.005543108098208904,\n",
              " 0.016395632177591324,\n",
              " -0.02363882027566433,\n",
              " 0.0009425705065950751,\n",
              " 0.039149001240730286,\n",
              " -0.028608717024326324,\n",
              " 0.008749728091061115,\n",
              " 0.02676941081881523,\n",
              " 0.022505301982164383,\n",
              " -0.01551873330026865,\n",
              " -0.02304786443710327,\n",
              " 0.029876016080379486,\n",
              " -0.016235848888754845,\n",
              " -0.03379601985216141,\n",
              " -0.03708561509847641,\n",
              " -0.027157563716173172,\n",
              " 0.05657950043678284,\n",
              " 0.01144383568316698,\n",
              " -0.02140752039849758,\n",
              " -0.022187160328030586,\n",
              " 0.060364507138729095,\n",
              " -0.019342700019478798,\n",
              " 0.026581399142742157,\n",
              " 0.003094704123213887,\n",
              " 0.07125630974769592,\n",
              " 0.003490856382995844,\n",
              " 0.003979733679443598,\n",
              " -0.00857103057205677,\n",
              " 0.04588211327791214,\n",
              " -0.017737241461873055,\n",
              " 0.01849258877336979,\n",
              " 0.021616686135530472,\n",
              " -0.02954580821096897,\n",
              " 0.023624323308467865,\n",
              " 0.03274970129132271,\n",
              " -0.014759482815861702,\n",
              " 0.010819805786013603,\n",
              " 0.08572103083133698,\n",
              " -0.04953201115131378,\n",
              " 0.008847820572555065,\n",
              " -0.015231981873512268,\n",
              " -0.011408028192818165,\n",
              " 0.00686761736869812,\n",
              " -0.06087072566151619,\n",
              " 0.003385981312021613,\n",
              " -0.011373957619071007,\n",
              " 0.08649294823408127,\n",
              " -0.015550238080322742,\n",
              " 0.033261723816394806,\n",
              " -0.019013768061995506,\n",
              " -0.009828219190239906,\n",
              " -0.02150348573923111,\n",
              " -0.049555741250514984,\n",
              " 0.05393797159194946,\n",
              " -0.03516138345003128,\n",
              " 0.030149532482028008,\n",
              " -0.0067240772768855095,\n",
              " -0.005924764089286327,\n",
              " -0.0005124572198837996,\n",
              " 0.02182702347636223,\n",
              " -0.024280045181512833,\n",
              " 0.017760226503014565,\n",
              " 0.01958504505455494,\n",
              " 0.01649981364607811,\n",
              " -0.01454902347177267,\n",
              " -0.04116690158843994,\n",
              " -0.0041409810073673725,\n",
              " -0.00018029368948191404,\n",
              " 0.014881630428135395,\n",
              " -0.03518243134021759,\n",
              " 0.009813439100980759,\n",
              " -0.019013121724128723,\n",
              " 0.06914984434843063,\n",
              " -0.008100531063973904,\n",
              " -0.008336849510669708,\n",
              " -0.023673972114920616,\n",
              " 0.02749529853463173,\n",
              " 0.02785167284309864,\n",
              " -0.033508121967315674,\n",
              " -0.044866882264614105,\n",
              " -0.035768814384937286,\n",
              " 0.01721969246864319,\n",
              " -0.03592342883348465,\n",
              " 0.091483473777771,\n",
              " 0.038686126470565796,\n",
              " -0.008785831741988659,\n",
              " -0.018611576408147812,\n",
              " -0.058629244565963745,\n",
              " -0.05423387140035629,\n",
              " 0.08690273016691208,\n",
              " -0.02196221984922886,\n",
              " -0.04447387158870697,\n",
              " -0.03882947191596031,\n",
              " -0.012508704327046871,\n",
              " -0.022004742175340652,\n",
              " -0.049519725143909454,\n",
              " -0.013344084843993187,\n",
              " -0.05640817806124687,\n",
              " -0.032106343656778336,\n",
              " 0.00018158808234147727,\n",
              " 0.06128600612282753,\n",
              " -0.0034675290808081627,\n",
              " -0.0093993516638875,\n",
              " -0.03117607906460762,\n",
              " -0.021790603175759315,\n",
              " 0.028282271698117256,\n",
              " 0.05205480381846428,\n",
              " -0.030634893104434013,\n",
              " -0.004588782787322998,\n",
              " -0.0017178902635350823,\n",
              " 0.03401210159063339,\n",
              " 0.01829884573817253,\n",
              " 0.011611397378146648,\n",
              " -0.04495840147137642,\n",
              " 0.02696705050766468,\n",
              " 0.005919818766415119,\n",
              " 0.06709124892950058,\n",
              " 0.048177361488342285,\n",
              " -0.02238812856376171,\n",
              " -0.012375903315842152,\n",
              " -0.0958530381321907,\n",
              " 0.04503922536969185,\n",
              " -0.030322376638650894,\n",
              " -0.008945213630795479,\n",
              " 0.06996948271989822,\n",
              " -0.008050680160522461,\n",
              " -0.004476029891520739,\n",
              " 0.0048675513826310635,\n",
              " -0.057685647159814835,\n",
              " -0.018241845071315765,\n",
              " 0.002281843451783061,\n",
              " 0.0024967691861093044,\n",
              " 0.03428806737065315,\n",
              " -0.004497664049267769,\n",
              " 0.005308899562805891,\n",
              " 0.015459887683391571,\n",
              " 0.010959388688206673,\n",
              " -0.0022336719557642937,\n",
              " 0.04430835694074631,\n",
              " -0.03384709358215332,\n",
              " 0.03115876205265522,\n",
              " -0.027875270694494247,\n",
              " 0.007387059740722179,\n",
              " 0.0031055959407240152,\n",
              " 0.06055508553981781,\n",
              " 0.0796194076538086,\n",
              " -0.030547892674803734,\n",
              " -0.02289670705795288,\n",
              " 0.04941130802035332,\n",
              " 0.03767145052552223,\n",
              " 0.02475978061556816,\n",
              " -0.04933743178844452,\n",
              " -0.04318907484412193,\n",
              " -0.02733851596713066,\n",
              " 0.0009193997248075902,\n",
              " 0.01503128744661808,\n",
              " 0.06630732864141464,\n",
              " -0.051655665040016174,\n",
              " -0.07833248376846313,\n",
              " -0.03768754005432129,\n",
              " 0.020200682803988457,\n",
              " 0.008699296973645687,\n",
              " 0.010983753018081188,\n",
              " -0.01866202801465988,\n",
              " 0.0007112672319635749,\n",
              " -0.026263149455189705,\n",
              " 0.03081987239420414,\n",
              " 0.016045259311795235,\n",
              " 0.05230285972356796,\n",
              " -0.04657033458352089,\n",
              " 0.030525216832756996,\n",
              " 0.009099193848669529,\n",
              " -0.012801758013665676,\n",
              " -0.02315972000360489,\n",
              " -0.0192971583455801,\n",
              " 0.004379142541438341,\n",
              " -0.03240801766514778,\n",
              " 0.05669579282402992,\n",
              " 0.010731196962296963,\n",
              " 0.04139949753880501,\n",
              " -0.027756765484809875,\n",
              " -0.06014345586299896,\n",
              " 0.09955500811338425,\n",
              " -0.00199900777079165,\n",
              " -0.011435561813414097,\n",
              " -0.018484430387616158,\n",
              " 0.039257291704416275,\n",
              " 0.0641617700457573,\n",
              " 0.026817118749022484,\n",
              " 0.026741068810224533,\n",
              " -0.04054086655378342,\n",
              " -0.004113438073545694,\n",
              " 0.06471697986125946,\n",
              " -9.438148845219985e-05]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "# from langchain import OpenAIEmbeddings\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents,\n",
        "    embedding=embeddings)"
      ],
      "metadata": {
        "id": "DVdmMls9TTrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " list(dir(vectorstore))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri3FL-73RtxW",
        "outputId": "794768f5-dd9d-4a01-db46-5c1cf8e61937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Chroma__ensure_collection',\n",
              " '_Chroma__query_collection',\n",
              " '_LANGCHAIN_DEFAULT_COLLECTION_NAME',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_asimilarity_search_with_relevance_scores',\n",
              " '_chroma_collection',\n",
              " '_client',\n",
              " '_client_settings',\n",
              " '_collection',\n",
              " '_collection_metadata',\n",
              " '_collection_name',\n",
              " '_cosine_relevance_score_fn',\n",
              " '_embedding_function',\n",
              " '_euclidean_relevance_score_fn',\n",
              " '_get_retriever_tags',\n",
              " '_max_inner_product_relevance_score_fn',\n",
              " '_persist_directory',\n",
              " '_select_relevance_score_fn',\n",
              " '_similarity_search_with_relevance_scores',\n",
              " 'aadd_documents',\n",
              " 'aadd_texts',\n",
              " 'add_documents',\n",
              " 'add_images',\n",
              " 'add_texts',\n",
              " 'adelete',\n",
              " 'afrom_documents',\n",
              " 'afrom_texts',\n",
              " 'aget_by_ids',\n",
              " 'amax_marginal_relevance_search',\n",
              " 'amax_marginal_relevance_search_by_vector',\n",
              " 'as_retriever',\n",
              " 'asearch',\n",
              " 'asimilarity_search',\n",
              " 'asimilarity_search_by_vector',\n",
              " 'asimilarity_search_with_relevance_scores',\n",
              " 'asimilarity_search_with_score',\n",
              " 'delete',\n",
              " 'delete_collection',\n",
              " 'embeddings',\n",
              " 'encode_image',\n",
              " 'from_documents',\n",
              " 'from_texts',\n",
              " 'get',\n",
              " 'get_by_ids',\n",
              " 'max_marginal_relevance_search',\n",
              " 'max_marginal_relevance_search_by_vector',\n",
              " 'override_relevance_score_fn',\n",
              " 'reset_collection',\n",
              " 'search',\n",
              " 'similarity_search',\n",
              " 'similarity_search_by_image',\n",
              " 'similarity_search_by_image_with_relevance_score',\n",
              " 'similarity_search_by_vector',\n",
              " 'similarity_search_by_vector_with_relevance_scores',\n",
              " 'similarity_search_with_relevance_scores',\n",
              " 'similarity_search_with_score',\n",
              " 'similarity_search_with_vectors',\n",
              " 'update_document',\n",
              " 'update_documents']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJXQbsgRTmET",
        "outputId": "c66e5490-a8a0-4cbe-9dd9-585dd007bc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7f1391307450>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.similarity_search(\"cat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P12_qrjLTq4V",
        "outputId": "f540a157-dc1f-4c2d-c192-d0de3bef64e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='a929b32e-0094-4833-8f33-8cb4bb756478', metadata={'source': 'memmal-pets-doc'}, page_content='Cats are independent pets that ofte enjoy their ownn space.'),\n",
              " Document(id='95368390-5fdc-43db-acf7-04ad790e1549', metadata={'source': 'memmal-pets-doc'}, page_content='Dogs are great compannions , known for their loyalty and friendliness'),\n",
              " Document(id='4fb42ea5-f068-49d6-adae-48ebe9081ab3', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginnners, requirinng relatively simple care.'),\n",
              " Document(id='7d4e185d-a4d6-437e-b5f4-76b57925fee0', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "await vectorstore.asimilarity_search(\"cat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3CAl4fHTyhN",
        "outputId": "61c45fcc-07b9-4a91-b4c0-c7bdf2e7fd0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='a929b32e-0094-4833-8f33-8cb4bb756478', metadata={'source': 'memmal-pets-doc'}, page_content='Cats are independent pets that ofte enjoy their ownn space.'),\n",
              " Document(id='95368390-5fdc-43db-acf7-04ad790e1549', metadata={'source': 'memmal-pets-doc'}, page_content='Dogs are great compannions , known for their loyalty and friendliness'),\n",
              " Document(id='4fb42ea5-f068-49d6-adae-48ebe9081ab3', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginnners, requirinng relatively simple care.'),\n",
              " Document(id='7d4e185d-a4d6-437e-b5f4-76b57925fee0', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note that providers implement different scores: Chroma here\n",
        "# returns a distance metric that should vary inversely with\n",
        "# similarity.\n",
        "\n",
        "vectorstore.similarity_search_with_score(\"cat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d20ms_3cURKL",
        "outputId": "648fbda8-04d9-4bb7-c07d-89c0a94560fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(id='a929b32e-0094-4833-8f33-8cb4bb756478', metadata={'source': 'memmal-pets-doc'}, page_content='Cats are independent pets that ofte enjoy their ownn space.'),\n",
              "  0.6782598495483398),\n",
              " (Document(id='95368390-5fdc-43db-acf7-04ad790e1549', metadata={'source': 'memmal-pets-doc'}, page_content='Dogs are great compannions , known for their loyalty and friendliness'),\n",
              "  1.0325783491134644),\n",
              " (Document(id='4fb42ea5-f068-49d6-adae-48ebe9081ab3', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginnners, requirinng relatively simple care.'),\n",
              "  1.104372501373291),\n",
              " (Document(id='7d4e185d-a4d6-437e-b5f4-76b57925fee0', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
              "  1.1072404384613037)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = embeddings.embed_query(\"cat\")\n",
        "vectorstore.similarity_search_by_vector(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JgL0oTSUpEU",
        "outputId": "3f5b4a69-c8a6-482f-ecdc-6573d8b580a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='a929b32e-0094-4833-8f33-8cb4bb756478', metadata={'source': 'memmal-pets-doc'}, page_content='Cats are independent pets that ofte enjoy their ownn space.'),\n",
              " Document(id='95368390-5fdc-43db-acf7-04ad790e1549', metadata={'source': 'memmal-pets-doc'}, page_content='Dogs are great compannions , known for their loyalty and friendliness'),\n",
              " Document(id='4fb42ea5-f068-49d6-adae-48ebe9081ab3', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginnners, requirinng relatively simple care.'),\n",
              " Document(id='7d4e185d-a4d6-437e-b5f4-76b57925fee0', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrievers\n",
        "\n",
        "- with langchain"
      ],
      "metadata": {
        "id": "CboLtZaUU7kI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retriever = RunnableLambda(\n",
        "    vectorstore.similarity_search).bind(k=1) # select top result\n",
        "\n",
        "retriever.batch([\"shark\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeC9pYuYUzWB",
        "outputId": "c0f5d2b2-eebf-4c51-ffcc-25f3942b9235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Document(id='4fb42ea5-f068-49d6-adae-48ebe9081ab3', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginnners, requirinng relatively simple care.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\",\n",
        "                             api_key = userdata.get(\"GOOGLE_API_KEY\"))"
      ],
      "metadata": {
        "id": "_GbonWo0WbmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "{question}\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0oNFatVxW_az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"human\",message)]\n",
        ")"
      ],
      "metadata": {
        "id": "Rw9yyBIEYDq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = {\"context\":retriever,\"question\":RunnablePassthrough()} | prompt | llm"
      ],
      "metadata": {
        "id": "0Ue4GsThYS_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"tell me about dog?\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEWi8zIMYimA",
        "outputId": "5baf5028-7ee6-42da-c745-f02921e9893e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided text, dogs are great companions known for their loyalty and friendliness.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Face detection with embedding**\n",
        "\n",
        "#  facenet -> for face detection\n",
        "# yamnet -> fro sound classification\n",
        "#"
      ],
      "metadata": {
        "id": "oj_cFJ6JZ-BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq facenet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyo0wwUzZH-v",
        "outputId": "326bc0e7-d64e-4888-815a-05cc5f700ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m804.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m960.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KDWcgK9aJ7J",
        "outputId": "1d714bdf-cd46-4cdc-ea03-bd514e94ae66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/4.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/4.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/4.5 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 11.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn # Changed 'toch' to 'torch'\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms # Changed 'tochvision' to 'torchvision'\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "XxIc05LCbTET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cbfc2834a25e466aa9f0b9a765dbbacf",
            "5db41a9b21e34665ab68c2e9a8f8594f",
            "905bc53f565e423e9baf615a9b70c3db",
            "f3510f8149604598ad60fa6d9baf750f",
            "5a780449c663490a91d66f6ed69b0459",
            "7871f8d4b3ec4878be2540a1a03b0325",
            "8be7f5215e0c4f0d932cc2fe8aec8aa5",
            "fb0b34dab0e6456cb85a849db20a3581",
            "6bd7f3c8ff8743f0a600e0af761c8c4b",
            "1c1d12f63d184032a1b51cb92981af87",
            "85bcbe8f28ff404fa94da8b58f11f594"
          ]
        },
        "id": "THmtbdeJb4BM",
        "outputId": "8018897c-f06c-4a2d-acba-79f4ad046d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbfc2834a25e466aa9f0b9a765dbbacf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InceptionResnetV1(\n",
              "  (conv2d_1a): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2a): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2b): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2d_3b): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4a): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4b): BasicConv2d(\n",
              "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (repeat_1): Sequential(\n",
              "    (0): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_6a): Mixed_6a(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_2): Sequential(\n",
              "    (0): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (9): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_7a): Mixed_7a(\n",
              "    (branch0): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_3): Sequential(\n",
              "    (0): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (block8): Block8(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
              "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (logits): Linear(in_features=512, out_features=8631, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepcocessing function to transform the image into a tensor\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.456],std=[0.229,0.224,0.25])\n",
        "      ])\n",
        "    return preprocess(image).unsqueeze(0)\n",
        "\n",
        "def create_image_embedding(image_path):\n",
        "    try:\n",
        "      input_tensor = preprocess_image(image_path)\n",
        "      with torch.no_grad():\n",
        "        embedding = model(input_tensor)\n",
        "      return embeddings.squeeze().numpy()\n",
        "    except Exception as e:\n",
        "      print(f\"Error creating embedding: {e}\")\n",
        "      return None\n"
      ],
      "metadata": {
        "id": "muqrSC_zcaOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "metadata": {
        "id": "XoiO_POv0K67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def save_image_from_url(image_url, image_name):\n",
        "  \"\"\"\n",
        "  Downloads an image from a URL and saves it to the 'images' folder.\n",
        "\n",
        "  Args:\n",
        "      image_url: The URL of the image to download.\n",
        "      image_name: The name of the file to save the image as.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if not os.path.exists(\"images\"):\n",
        "      os.makedirs(\"images\")\n",
        "\n",
        "    # Create the full image path using os.path.join\n",
        "    image_path = os.path.join(\"images\", image_name)\n",
        "\n",
        "    response = requests.get(image_url, stream=True) # Use stream=True for large files\n",
        "    response.raise_for_status()\n",
        "\n",
        "    with open(image_path, 'wb') as file:\n",
        "      for chunk in response.iter_content(chunk_size=8192):\n",
        "        file.write(chunk)\n",
        "    print(f\"Image saved as {image_path}\")\n",
        "\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading image: {e}\")\n",
        "  except Exception as e:\n",
        "    print(f\"Unknown error: {e}\")"
      ],
      "metadata": {
        "id": "r7Q0cblP0TXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_image_from_url(\"https://www.instagram.com/imrankhan.pti/?hl=en\",\"sulman1\")\n",
        "save_image_from_url(\"https://images.app.goo.gl/cJrpQnxwjKVe4RMQ7.png\",\"sulman2\")\n",
        "save_image_from_url(\"https://images.app.goo.gl/Kn4tzerVbjkTFE3v7.png\",\"imran1\")\n",
        "save_image_from_url(\"https://images.app.goo.gl/A93y3DywWGDHPCSo6.png\",\"hanzla1\")\n",
        "save_image_from_url(\"https://images.app.goo.gl/gTCbLHmK53HwKfSu6.png\",\"kinza2\")\n",
        "save_image_from_url(\"https://images.app.goo.gl/iaFgeGEg3Lt6vPKv7.png\",\"kinza1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRPSQjZ-GnhL",
        "outputId": "62137e4a-94d5-4e3a-e43b-0890afd3b965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading image: 429 Client Error: Too Many Requests for url: https://www.instagram.com/accounts/login/?next=https%3A%2F%2Fwww.instagram.com%2Fimrankhan.pti%2F%3Fhl%3Den&is_from_rle\n",
            "Error downloading image: 400 Client Error: Bad Request for url: https://images.app.goo.gl/cJrpQnxwjKVe4RMQ7.png\n",
            "Error downloading image: 400 Client Error: Bad Request for url: https://images.app.goo.gl/Kn4tzerVbjkTFE3v7.png\n",
            "Error downloading image: 400 Client Error: Bad Request for url: https://images.app.goo.gl/A93y3DywWGDHPCSo6.png\n",
            "Error downloading image: 400 Client Error: Bad Request for url: https://images.app.goo.gl/gTCbLHmK53HwKfSu6.png\n",
            "Error downloading image: 400 Client Error: Bad Request for url: https://images.app.goo.gl/iaFgeGEg3Lt6vPKv7.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tfz1dnf7JXxu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}